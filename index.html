<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>MIRAGE: A Benchmark for Multimodal Information‑Seeking and Reasoning in Agricultural Expert‑Guided Conversations</title>
    <meta name="description" content="MIRAGE is a benchmark for multimodal expert‑level reasoning and decision‑making in agricultural consultative interactions." />
    <meta name="keywords" content="MIRAGE, benchmark, agriculture, multimodal, vision‑language model, expert reasoning, information seeking" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Icons & Fonts -->
    <link rel="icon" href="./static/figures/logo/MIRAGE_32x32.png" />
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

    <!-- Styles -->
    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <style>
        body { font-family: sans-serif; }
        .lb-wrapper {max-width:1100px;margin:40px auto 60px;}

        .sectionsubtitle { text-align: center; font-size: 1.6em; font-weight: bold; margin-bottom: 25px; }
        .legend { text-align: center; margin-bottom: 25px; }
        .legend-item { display: inline-block; padding: 8px 16px; margin: 0 8px; border-radius: 8px; font-size: 0.9em; }
        .legend-open { background-color: #e6f0ff; }
        .legend-proprietary { background-color: #ffe6e6; }

        tr.open-col td {background:#e6f0ff !important;}
        tr.proprietary-col td {background:#ffe6e6 !important;}
        td.best {font-weight:bold;}

        #lb thead th {
          text-align: center;
          vertical-align: middle;
        }
        
        #lb th.separator,
        #lb td.separator {
          border-right: 1px solid #d3d3d3;
        }

   /* Description 样式优化 */
  .description-wrapper {
    margin-top: 48px;
    padding: 32px 38px;
    background: linear-gradient(180deg,#fafafa 0%,#f5f5f5 100%);
    border: 1px solid #e0e0e0;
    border-radius: 10px;
    font-size: 1rem;
    line-height: 1.7;
  }
  /* 一级无序列表：任务 */
  .description-wrapper > ul {
    margin: 1.2em 0 0 0;
    padding-left: 1.1em;
    list-style-type: disc;
  }
  /* 二级列表：指标 */
  .description-wrapper ul ul {
    margin-top: .4em;
    padding-left: 1.3em;
    list-style-type: circle;
  }
  /* 每个 <li> 之间额外留空 */
  .description-wrapper li + li { margin-top: .55em; }
  /* 公式自动换行防止溢出 */
  .description-wrapper .math-inline { white-space:normal; }

    </style>
          <!-- Scripts -->
    <script src="https://kit.fontawesome.com/fff5b27ec1.js" crossorigin="anonymous"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/index.js"></script>
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">

    <script defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>

    <script defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body);"></script>


  </head>
  <body>
    <!-- ‑‑‑‑ NAVBAR ‑‑‑‑ -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
    </nav>

    <!-- ‑‑‑‑ HERO SECTION ‑‑‑‑ -->
    <!-- <section class="hero is-medium is-light"> -->
    <section class="hero">
      <div class="hero-body">
        <div class="container has-text-centered">
          <h1 class="title is-1">
            <img src="static/figures/logo/MIRAGE_512x512.png" style="width:1.2em; vertical-align:middle;" alt="Logo" />
            <span style="vertical-align:middle">MIRAGE</span>
          </h1>
          <h2 class="subtitle is-3">A Benchmark for Multimodal Information‑Seeking and Reasoning in Agricultural Expert‑Guided Conversations</h2>
          
          <!-- AUTHORS -->
          <div class="is-size-5 publication-authors">
            <p>
              <span class="author-block">Vardhan Dongre<sup>1*</sup>,</span>
              <span class="author-block">Chi Gui<sup>1*</sup>,</span>
              <span class="author-block">Hooshang Nayyeri<sup>2</sup>,</span>
              <span class="author-block">Shubham Garg<sup>2</sup>,</span>
              <span class="author-block">Gokhan Tür<sup>1</sup>,</span>
              <span class="author-block">Dilek Hakkani‑Tür<sup>1</sup>,</span>
              <span class="author-block">Vikram Adve<sup>1</sup></span>
            </p>
          </div>

          <!-- Add one image logo plus a link -->
          <div class="mt-4 has-text-centered">
            <a href="https://aifarms.illinois.edu/" target="_blank" style="text-decoration: none;">
              <img src="static/figures/logo/AIFARMS.jpg" alt="AIFARMS" style="height: 60px; vertical-align: middle; margin-right: 10px;" />
            </a>
          </div>

            <p class="is-size-6 mt-2">
              <sup>1</sup>University of Illinois Urbana-Champaign &nbsp;
              <sup>2</sup>Amazon
            </p>
            <p class="is-size-5"><span class="has-text-grey">* Equal contributions</span></p>
          </div>

          <!-- LINKS -->
          <div class="buttons is-centered mt-4">
            <span class="link-block">
              <a href="https://huggingface.co/datasets/MIRAGE-Benchmark/MIRAGE" class="external-link button is-normal is-rounded is-dark">
                <span class="icon" style="font-size:18px">🤗</span>
                <span>Dataset</span>
              </a>        
            </span>
            <span class="link-block">
              <a href="https://github.com/vardhandongre/MIRAGE-Benchmark" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <!-- <a href="#leaderboard" class="button is-dark is-rounded"><span class="icon"><i class="fas fa-trophy"></i></span><span>Leaderboard</span></a> -->
          </div>
        </div>
      </div>
    </section>

    <!-- ‑‑‑‑ ABSTRACT ‑‑‑‑ -->
    <section id="abstract" class="section">
      <div class="container is-max-desktop content">
      <div>
        <h2 class="sectionsubtitle">Abstract</h2>
      </div>
        <p>
          We introduce <strong>MIRAGE</strong>, a new benchmark for multimodal expert‑level reasoning and decision‑making in consultative interaction settings. Designed for the agriculture domain, MIRAGE captures the full complexity of expert consultations by combining natural user queries, expert‑authored responses, and image‑based context, offering a high‑fidelity benchmark for evaluating models on grounded reasoning, clarification strategies, and long‑form generation.
        </p>
        <p>
          Grounded in over 35,000 real user–expert interactions and curated through a carefully designed multi‑step pipeline, MIRAGE spans diverse crop health, pest diagnosis, and crop management scenarios. The benchmark includes more than 7,000 unique biological entities, covering plant species, pests, and diseases—making it one of the most taxonomically diverse benchmarks available for vision‑language models.
        </p>
        <p>
          Unlike existing benchmarks that rely on well‑specified user inputs and closed‑set taxonomies, MIRAGE features underspecified, context‑rich scenarios with open‑world settings, requiring models to infer latent knowledge gaps, handle rare entities, and proactively guide or respond within the interaction.
        </p>
        <p>
          We evaluate more than 20 frontier vision‑language models using an ensemble of reasoning language models as evaluators, highlighting the significant challenges posed by MIRAGE. Despite strong performance on conventional benchmarks, state‑of‑the‑art VLMs struggle on MIRAGE—particularly in scenarios encountering rare entities and addressing open‑ended user requests. Fine‑tuning <em>Qwen2.5‑VL</em> models on MIRAGE yields measurable gains, demonstrating MIRAGE’s value both as a benchmark and a development suite for in‑domain visual reasoning and conversational decision‑making.
        </p>
      </div>
    </section>

    <!-- MIRAGE-MMST SECTION -->
    <section id="MIRAGE-MMST">
      <section id="MIRAGE-MMST Title" class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-3">
          <!-- style="height: 4rem; margin-right: 0.4rem; position: relative; top: 0.7rem;" -->
        <img src="static/figures/logo/ST_512x512.png" alt="Icon" style="height: 4rem; position: relative; top: 0.7rem;"/>MIRAGE-MMST: Multimodal Singleturn Benchmark
        </h1>
      </div>
      </section>      
      <div class="container is-max-desktop">
        <!-- Overview -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 2rem;">MIRAGE-MMST Overview</h2>
            <p style="margin-bottom: 1.5rem;">
                <strong>MIRAGE-MMST</strong> is a benchmark designed to assess expert-level, single-turn reasoning in multimodal agricultural consultations. The task setup is similar to a Long-form VQA task. Each instance consists of a natural language question paired with one or more user-provided images and associated metadata (e.g., timestamp, location). Each instance consists of a natural language question <em>q</em>, an associated image set <em>I = {i<sub>1</sub>, …, i<sub>m</sub>}</em>, and metadata <em>meta ∈ M</em>. Formally, a single-turn instance is represented as a triplet <em>(q, I, meta) ∈ Q × I<sup>m</sup> × M</em>, and the model must generate a structured response <em>r = (e, c ∨ m)</em>, where <em>e</em> denotes identified entities (e.g., crop, pest, disease), <em>c</em> is a causal explanation, and <em>m</em> is a management recommendation, if requested. The task evaluates the model's ability to reason causally about visual symptoms, identify relevant agronomic entities, and, when prompted, generate detailed management recommendations grounded in the observed evidence.
            </p>
            
            <p style="margin-bottom: 1.5rem;">
                To support varying levels of difficulty and contextual grounding, MIRAGE-MMST is divided into two subsets: a <strong>Standard</strong> subset, consisting of self-contained questions that can be answered using only the provided text and image, and a <strong>Contextual</strong> subset, where successful interpretation depends on implicit information such as time, location, or agricultural context not present in the input. The standard subset evaluates a model's ability to identify entities, infer causal relationships, and generate explanatory or recommendation-based responses. In contrast, the contextual subset contains queries with latent information gaps and elliptical language, requiring models to reconstruct missing context using external priors. We first manually annotated a seed set of contextual examples and then adopted an automated classifier to separate the full dataset.
            </p>

        <!-- Image for Statistic -->
        <div class="has-text-centered">
          <img src="static/figures/MMST/MMST_Statistic.jpg" alt="MIRAGE-MMST Statistics" style="max-width: 60%; height: auto;" title="MIRAGE-MMST Statistics" />
        </div>
        </div>

        <!-- Leaderboard -->
        <div class="box has-text-centered">
      <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet">
      <link href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">

    <div class="lb-wrapper">
      <h2 class="sectionsubtitle">MIRAGE-MMST Leaderboard</h2>
      <div class="legend">
        <span class="legend-item legend-open">Open-Source</span>
        <span class="legend-item legend-proprietary">Proprietary</span>
      </div>

      <table id="lb" class="display stripe" style="width:100%">
        <thead>
          <tr>
            <th rowspan="2" class="separator">Name</th>
            <th colspan="3" class="separator">Identification</th>
            <th colspan="5" class="separator">Management</th>
            <th rowspan="2">Overall</th>
          </tr>
          <tr>
            <th class="id-col">Acc</th>
            <th class="id-col">Reason</th>
            <th class="id-col">WS</th>
            <th class="mg-col">Acc</th>
            <th class="mg-col">Rel</th>
            <th class="mg-col">Comp</th>
            <th class="mg-col">Pars</th>
            <th class="mg-col">WS</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>

    <div class="description-wrapper content has-text-justified">
      <p>
        This leaderboard benchmarks large vision-language models on the
        <strong>MMST-Standard</strong> dataset.  
        The benchmark utilizes LLMs as Judges method. Scores are averaged over three open-source reasoning models:
        <em>DeepSeek-R1-Distill-Llama-70B</em>,
        <em>Qwen2-32B</em>, and
        <em>Phi-3-Reasoning</em>.
      </p>

      <p>The evaluation comprises two tasks:</p>

      <ul>
        <li>
          <strong>Identification&nbsp;(ID) Task</strong>
          <ul>
            <li><strong>Acc</strong> – identification accuracy (0&nbsp;–&nbsp;1)</li>
            <li><strong>Reason</strong> – reasoning accuracy (0&nbsp;–&nbsp;4)</li>
            <li>
              <strong>ID-WS</strong> – weighted score  
              <span class="math-inline">
                WS&nbsp;=&nbsp;\(\dfrac{2 \times Acc + \tfrac{Reason}{4}}{3} \times 100\)
              </span>
            </li>
          </ul>
        </li>

        <li>
          <strong>Management&nbsp;(MG) Task</strong>
          <ul>
            <li>
              Metrics: <strong>Acc</strong> (Accuracy),
              <strong>Rel</strong> (Relevance),
              <strong>Comp</strong> (Completeness),
              <strong>Pars</strong> (Parsimony) — each 0&nbsp;–&nbsp;4
            </li>
            <li>
              <strong>MG-WS</strong> – weighted score  
              <span class="math-inline">
                WS&nbsp;=&nbsp;\(\dfrac{2 \times Acc + Rel + Comp + Pars}{20} \times 100\)
              </span>
            </li>
          </ul>
        </li>
      </ul>

      <p>
        <strong>Overall</strong> – average of the two weighted scores:  
        <span class="math-inline">\(\tfrac{ID\text{-}WS + MG\text{-}WS}{2}\)</span>
      </p>
    </div>
    </div>


    
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>

    <script>
    fetch("leaderboards/MMST_Standard.json")
      .then(r=>r.json())
      .then(rows=>{
        const metrics = ["id_acc_pct","id_reason",
                        "mg_acc","mg_rel","mg_comp","mg_pars",
                        "id_ws","mg_ws","overall"];
        const maxVal = Object.fromEntries(
          metrics.map(m=>[m,Math.max(...rows.map(r=>r[m]))]) );

        const table = $('#lb').DataTable({
          data: rows,
          dom : 't',
          paging: false,
          order:[[9,'desc']],
          columns:[
            {title:"Model", data:"model", className: "separator"},
            {title:"Acc",    data:"id_acc_pct", className:"id-col"},
            {title:"Reason", data:"id_reason",  className:"id-col"},
            {title:"WS",     data:"id_ws",      className:"id-col separator"},
            {title:"Acc",  data:"mg_acc",  className:"mg-col"},
            {title:"Rel",  data:"mg_rel",  className:"mg-col"},
            {title:"Comp", data:"mg_comp", className:"mg-col"},
            {title:"Pars", data:"mg_pars", className:"mg-col"},
            {title:"WS",   data:"mg_ws",   className:"mg-col separator"},
            {title:"Overall", data:"overall"}
          ],
          createdRow:(row,data)=>{
            $(row).addClass(
              data.group==='open' ? 'open-col' : 'proprietary-col');

            metrics.forEach((m,i)=>{
              if(data[m]===maxVal[m]) $('td',row).eq(i+1).addClass('best');
            });
          }
        });
      });
    </script>
    </section>

    <section id="MIRAGE-MMMT">
      <section id="MIRAGE-MMMT Title" class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-3">
        <img src="static/figures/logo/MT_512x512.png" alt="Icon" style="height: 4rem; margin-right: 0.4rem; position: relative; top: 0.7rem;" />MIRAGE-MMMT: Multimodal Multiturn Benchmark
        </h1>      
      </div>
      </section>      
      <div class="container is-max-desktop">
        <!-- Overview -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 2rem;">MIRAGE-MMST Overview</h2>
            <p style="margin-bottom: 1.5rem;">
                <strong>MIRAGE-MMMT</strong> is a multimodal decision-making task, grounded in real-world agricultural consultations. Users pose complex, often image-supported questions about plant health, pest identification, growing conditions, and other agronomic concerns. Each dialogue reflects a practical scenario in which the expert must reason over conversation history and visual context to decide: (1) whether to respond with guidance based on what is known, or (2) whether to pause and seek additional input to resolve a knowledge gap. This introduces a decision-making challenge tightly coupled with natural language generation.
            </p>
        <!-- Image for Statistic -->
        <div class="has-text-centered">
          <img src="static/figures/MMMT/MMMT_Statistic.jpg" alt="MIRAGE-MMMT Statistics" style="max-width: 30%; height: auto;" />
        </div>
        </div>

        <!-- Leaderboard -->
        <h2 class="sectionsubtitle">MIRAGE-MMMT Leaderboard</h2>
        <div class="box has-text-centered">
        <p class="is-size-5">Leaderboard — coming soon</p>
      </div>
    </section>

    <footer class="footer">
      <div class="content has-text-centered">
        <p>
          Website template adapted from <a href="https://nerfies.github.io/">Nerfies</a> under CC BY‑SA‑4.0.
        </p>
      </div>
    </footer>
  </body>
</html>
