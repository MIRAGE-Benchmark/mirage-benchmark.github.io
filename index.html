<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>MIRAGE: A Benchmark for Multimodal Informationâ€‘Seeking and Reasoning in Agricultural Expertâ€‘Guided Conversations</title>
    <meta name="description" content="MIRAGE is a benchmark for multimodal expertâ€‘level reasoning and decisionâ€‘making in agricultural consultative interactions." />
    <meta name="keywords" content="MIRAGE, benchmark, agriculture, multimodal, visionâ€‘language model, expert reasoning, information seeking" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Icons & Fonts -->
    <link rel="icon" type="image/png" sizes="32x32" href="./static/figures/logo/MIRAGE_32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="./static/figures/logo/MIRAGE_32x32.png" />
    <link rel="apple-touch-icon" sizes="180x180" href="./static/figures/logo/MIRAGE_512x512.png" />
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

    <!-- Styles -->
    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <script src="https://kit.fontawesome.com/fff5b27ec1.js" crossorigin="anonymous"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/index.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css" />
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">

    <script defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>

    <script defer
            src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
            onload="renderMathInElement(document.body);"></script>

    <link rel="stylesheet" href="./static/css/mirage.css" />
  </head>
  <body>
    <!-- â€‘â€‘â€‘â€‘ NAVBAR â€‘â€‘â€‘â€‘ -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
    </nav>

    <!-- â€‘â€‘â€‘â€‘ HERO SECTION â€‘â€‘â€‘â€‘ -->
    <!-- <section class="hero is-medium is-light"> -->
    <section class="hero">
      <div class="hero-body">
        <div class="container has-text-centered">
          <h1 class="title is-1">
            <img src="static/figures/logo/MIRAGE-logo.png" style="height:4em; vertical-align:middle;" alt="MIRAGE Logo" />
          </h1>
          <h2 class="subtitle is-3">A Benchmark for Multimodal Informationâ€‘Seeking and Reasoning in Agricultural Expertâ€‘Guided Conversations</h2>
          
          <!-- AUTHORS -->
          <div class="is-size-5 publication-authors">
            <p>
              <span class="author-block"><a href="https://vardhandongre.github.io/" target="_blank">Vardhan Dongre</a><sup>1*</sup>,</span>
              <span class="author-block"><a href="https://chigui0.github.io/" target="_blank">Chi Gui</a><sup>1*</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=RQ8m900AAAAJ&hl=en" target="_blank">Hooshang Nayyeri</a><sup>2</sup>,</span>
              <span class="author-block"><a href="https://www.linkedin.com/in/shubham8garg/" target="_blank">Shubham Garg</a><sup>2</sup>,</span>
              <span class="author-block"><a href="https://siebelschool.illinois.edu/about/people/faculty/gokhan" target="_blank">Gokhan Tur</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://siebelschool.illinois.edu/about/people/faculty/dilek" target="_blank">Dilek Hakkaniâ€‘TÃ¼r</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://vikram.cs.illinois.edu/" target="_blank">Vikram Adve</a><sup>1</sup></span>
            </p>
          </div>

          <!-- Add institutional logos -->
          <div class="mt-4 has-text-centered">
            <a href="https://aifarms.illinois.edu/" target="_blank" style="text-decoration: none;">
              <img src="static/figures/logo/logo_aifarms2.png" alt="AIFARMS" style="height: 60px; vertical-align: middle; margin-right: 15px;" />
            </a>
            <a href="https://www.amazon.com/" target="_blank" style="text-decoration: none;">
              <img src="static/figures/logo/amazon-logo.png" alt="Amazon" style="height: 75px; vertical-align: middle; margin-right: 15px;" />
            </a>
            <a href="https://digitalag.illinois.edu/" target="_blank" style="text-decoration: none;">
              <img src="static/figures/logo/cda-logo.png" alt="Center for Digital Agriculture" style="height: 60px; vertical-align: middle;" />
            </a>
          </div>

            <p class="is-size-5 mt-2">
              <sup>1</sup>University of Illinois Urbana-Champaign &nbsp;
              <sup>2</sup>Amazon
            </p>
            <p class="is-size-6"><span class="has-text-grey">* Equal contributions</span></p>
          </div>

          <!-- LINKS -->
          <div class="buttons is-centered mt-4">
            <span class="link-block">
              <a href="https://arxiv.org/abs/2506.20100" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-alt"></i>
                </span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://huggingface.co/datasets/MIRAGE-Benchmark/MIRAGE" class="external-link button is-normal is-rounded is-dark">
                <span class="icon" style="font-size:18px">ðŸ¤—</span>
                <span>Dataset</span>
              </a>        
            </span>
            <span class="link-block">
              <a href="https://github.com/MIRAGE-Benchmark/MIRAGE-Benchmark" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <button onclick="toggleAudioPlayer()" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-headphones"></i>
                </span>
                <span>Audio</span>
              </button>
            </span>
            <span class="link-block">
              <!-- Direct to Example Section -->
              <a href="#MIRAGE Benchmark Examples" class="external-link button is-normal is-rounded is-dark">
                <span>Examples</span>
              </a>
            </span>
            <span class="link-block">
              <!-- Direct to Error Analysis Section -->
              <a href="#error-analysis" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-chart-line"></i>
                </span>
                <span>Error Analysis</span>
              </a>
            </span>
          </div>

          <!-- Audio Player Section -->
          <div id="audioPlayerSection" class="has-text-centered mt-4" style="display: none;">
            <div class="box" style="max-width: 600px; margin: 0 auto;">
              <h3 class="title is-4">MIRAGE Audio Overview</h3>
              <audio controls style="width: 100%;">
                <source src="static/audio/MIRAGE_ EN2.wav" type="audio/wav">
                Your browser does not support the audio element.
              </audio>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- MAIN IMAGE SECTION -->
    <section class="section">
      <div class="container is-max-desktop has-text-centered">
        <img src="static/images/main.png" alt="MIRAGE Benchmark Overview" style="max-width: 100%; height: auto;" />
      </div>
    </section>

    <!-- ABSTRACT -->
    <section id="abstract" class="section">
      <div class="container is-max-desktop content">
      <div>
        <h2 class="sectionsubtitle">Abstract</h2>
      </div>
        <p>
          <strong>MIRAGE</strong> is a new multimodal benchmark designed to evaluate vision-language models in realistic expert consultation settings. MIRAGE incorporates natural user queries, expert responses, and images derived from real interactions between real users and domain experts. It presents challenges such as underspecified information and rare biological entities, which current models struggle with, highlighting a need for improved grounded reasoning, clarification abilities, and long-form response generation. The benchmark includes both single-turn (MIRAGE-MMST) and multi-turn (MIRAGE-MMMT) tasks, assessing not just accuracy, diagnostic parsimony but also the ability to simulate expert conversational decisions, such as whether to clarify or respond. 
        </p>
        <p>
          Drawing on approximately 285 000 real-world agricultural consultations from the <a href="https://ask.extension.org/" target="_blank">AskExtension platform</a> (218 431 single-turn Q&A and 66 962 multi-turn dialogues) and encompassing over 7 000 unique plant, pest, and disease entities, MIRAGE offers both multimodal single-turn and multimodal multi-turn challenges.
        </p>
        <p>
          MIRAGE provides a rigorous testbed for evaluating visionâ€“language models on critical AI capabilities: grounded reasoning, through complex cause-effect inference tasks; multimodal understanding, by requiring fine-grained recognition from real-world user images; and conversational decision-making, by simulating dynamic, multi-turn expert consultations that challenge models to clarify ambiguities or deliver immediate guidance.
        </p>
      </div>
    </section>

    <!-- MIRAGE-MMST SECTION -->
    <section id="MIRAGE-MMST">
      <section id="MIRAGE-MMST Title" class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-3">
          <!-- style="height: 4rem; margin-right: 0.4rem; position: relative; top: 0.7rem;" -->
        <img src="static/figures/logo/ST_512x512.png" alt="Icon" style="height: 4rem; position: relative; top: 0.7rem;"/>MIRAGE-MMST: Multimodal Singleturn Benchmark
        </h1>
      </div>
      </section>      
      <div class="container is-max-desktop">
        <!-- Overview -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 2rem;">MIRAGE-MMST Overview</h2>
            <p style="margin-bottom: 1.5rem;">
              <strong>MIRAGE-MMST</strong> is a benchmark designed to assess multimodal vision-language models on expert-level, single-turn agricultural consultations. Each instance includes a natural-language question, user-submitted images, and associated metadata (e.g., timestamp, location). Models must identify relevant agronomic entities, reason causally about observed visual symptoms, and generate explanatory or actionable management recommendations. 
            </p>

            <p style="margin-bottom: 1.5rem;">
              The benchmark features two subsets:
            </p>

            <ul style="list-style-type: none; margin-left: 2rem; margin-bottom: 1.5rem;">
              <li style="margin-bottom: 1rem;">
                <strong>Standard subset:</strong> Evaluates models' entity identification, causal reasoning, and recommendation generation using only provided text and images.
              </li>
              <li>
                <strong>Contextual subset:</strong> Assesses the models' abilities to reason over implicit contextual information (e.g., geographic or seasonal details) necessary for accurate interpretation and response.
              </li>
            </ul>

        <!-- Image for Statistic -->
        <div class="has-text-centered">
          <img src="static/figures/MMST/MMST_Statistic.jpg" alt="MIRAGE-MMST Statistics" style="max-width: 100%; width: 60%; height: auto; min-width: 300px;" title="MIRAGE-MMST Statistics" />
        </div>
        </div>

        <!-- Leaderboard -->
        <div class="box has-text-centered">
      <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet">
      <link href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">

    <div class="lb-wrapper">
      <h2 class="sectionsubtitle">MIRAGE-MMST Leaderboard</h2>
      <div class="legend">
        <span class="legend-item legend-open">Open-Source</span>
        <span class="legend-item legend-proprietary">Proprietary</span>
      </div>

      <table id="lb" class="display stripe" style="width:100%">
        <thead>
          <tr>
            <th rowspan="2" class="separator">Name</th>
            <th colspan="3" class="separator">Identification</th>
            <th colspan="5" class="separator">Management</th>
            <th rowspan="2">Overall</th>
          </tr>
          <tr>
            <th class="id-col">Acc</th>
            <th class="id-col">Reason</th>
            <th class="id-col">WS</th>
            <th class="mg-col">Acc</th>
            <th class="mg-col">Rel</th>
            <th class="mg-col">Comp</th>
            <th class="mg-col">Pars</th>
            <th class="mg-col">WS</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>

    <div class="description-wrapper content has-text-justified">
      <p>
        This leaderboard benchmarks large vision-language models on the
        <strong>MMST-Standard</strong> dataset.  
        The benchmark utilizes LLMs as Judges method. Scores are averaged over three open-source reasoning models:
        <em>DeepSeek-R1-Distill-Llama-70B</em>,
        <em>Qwen2-32B</em>, and
        <em>Phi-4-Reasoning</em>.
      </p>

      <p>The evaluation comprises two tasks:</p>

      <ul>
        <li>
          <strong>Identification&nbsp;(ID) Task</strong>
          <ul>
            <li><strong>Acc</strong> â€“ identification accuracy (0&nbsp;â€“&nbsp;1)</li>
            <li><strong>Reason</strong> â€“ reasoning accuracy (0&nbsp;â€“&nbsp;4)</li>
            <li>
              <strong>ID-WS</strong> â€“ weighted score  
              <span class="math-inline">
                WS&nbsp;=&nbsp;\(\dfrac{2 \times Acc + \tfrac{Reason}{4}}{3} \times 100\)
              </span>
            </li>
          </ul>
        </li>

        <li>
          <strong>Management&nbsp;(MG) Task</strong>
          <ul>
            <li>
              Metrics: <strong>Acc</strong> (Accuracy),
              <strong>Rel</strong> (Relevance),
              <strong>Comp</strong> (Completeness),
              <strong>Pars</strong> (Parsimony) â€” each 0&nbsp;â€“&nbsp;4
            </li>
            <li>
              <strong>MG-WS</strong> â€“ weighted score  
              <span class="math-inline">
                WS&nbsp;=&nbsp;\(\dfrac{2 \times Acc + Rel + Comp + Pars}{20} \times 100\)
              </span>
            </li>
          </ul>
        </li>
      </ul>

      <p>
        <strong>Overall</strong> â€“ average of the two weighted scores:  
        <span class="math-inline">\(\tfrac{ID\text{-}WS + MG\text{-}WS}{2}\)</span>
      </p>

      <h3 class="title is-5 mt-5">Metric Descriptions</h3>
      <div class="content">
        <h4 class="title is-6">Identification Task Metrics</h4>
        <ul>
          <li><strong>Accuracy (Acc):</strong> Measures the correctness of entity identification (e.g., plant species, pests, diseases)</li>
          <li><strong>Reasoning (Reason):</strong> Evaluates the quality of causal explanations for observed symptoms and conditions</li>
        </ul>

        <h4 class="title is-6">Management Task Metrics</h4>
        <ul>
          <li><strong>Accuracy (Acc):</strong> Measures the correctness of management recommendations</li>
          <li><strong>Relevance (Rel):</strong> Assesses how well the recommendations address the specific problem</li>
          <li><strong>Completeness (Comp):</strong> Evaluates whether all necessary management steps are included</li>
          <li><strong>Parsimony (Pars):</strong> Measures the efficiency and practicality of the recommendations (Occam's Razor)</li>
        </ul>
      </div>
    </div>
    </div>


    
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>

    <script>
    fetch("leaderboards/MMST_Standard.json")
      .then(r=>r.json())
      .then(rows=>{
        const metrics = ["id_acc_pct","id_reason",
                        "mg_acc","mg_rel","mg_comp","mg_pars",
                        "id_ws","mg_ws","overall"];
        const maxVal = Object.fromEntries(
          metrics.map(m=>[m,Math.max(...rows.map(r=>r[m]))]) );

        const table = $('#lb').DataTable({
          data: rows,
          dom : 't',
          paging: false,
          order:[[9,'desc']],
          columns:[
            {title:"Model", data:"model", className: "separator"},
            {title:"Acc",    data:"id_acc_pct", className:"id-col"},
            {title:"Reason", data:"id_reason",  className:"id-col"},
            {title:"WS",     data:"id_ws",      className:"id-col separator"},
            {title:"Acc",  data:"mg_acc",  className:"mg-col"},
            {title:"Rel",  data:"mg_rel",  className:"mg-col"},
            {title:"Comp", data:"mg_comp", className:"mg-col"},
            {title:"Pars", data:"mg_pars", className:"mg-col"},
            {title:"WS",   data:"mg_ws",   className:"mg-col separator"},
            {title:"Overall", data:"overall"}
          ],
          createdRow:(row,data)=>{
            $(row).addClass(
              data.group==='open' ? 'open-col' : 'proprietary-col');

            metrics.forEach((m,i)=>{
              if(data[m]===maxVal[m]) $('td',row).eq(i+1).addClass('best');
            });
          }
        });
      });
    </script>
    </section>

    <!-- MIRAGE-MMMT SECTION -->
    <section id="MIRAGE-MMMT">
      <section id="MIRAGE-MMMT Title" class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-3">
        <img src="static/figures/logo/MT_512x512.png" alt="Icon" style="height: 4rem; margin-right: 0.4rem; position: relative; top: 0.7rem;" />MIRAGE-MMMT: Multimodal Multiturn Benchmark
        </h1>      
      </div>
      </section>      
      <div class="container is-max-desktop">
        <!-- Overview -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 2rem;">MIRAGE-MMMT Overview</h2>
            <p style="margin-bottom: 1.5rem;">
                <strong>MIRAGE-MMMT</strong> is a multimodal decision-making task, grounded in real-world agricultural consultations. Users pose complex, often image-supported questions about plant health, pest identification, growing conditions, and other agronomic concerns. Each dialogue reflects a practical scenario in which the expert must reason over conversation history and visual context to decide: (1) whether to respond with guidance based on what is known, or (2) whether to pause and seek additional input to resolve a knowledge gap. This introduces a decision-making challenge tightly coupled with natural language generation.
            </p>
        <!-- Image for Statistic -->
        <div class="has-text-centered">
          <img src="static/figures/MMMT/MMMT_Statistic.jpg" alt="MIRAGE-MMMT Statistics" style="max-width: 100%; width: 30%; height: auto; min-width: 250px;" />
        </div>

        <!-- MMMT Task Example -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 4rem;">MIRAGE-MMMT Task Example</h2>
        <div class="has-text-centered">
          <img src="static/figures/MMMT/mmmt.png" alt="MIRAGE-MMMT Task Example" style="max-width: 100%; width: 80%; height: auto; min-width: 280px;" />
        </div>
        </div>

        <!-- Leaderboard -->
        <div class="box has-text-centered">
      <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css" rel="stylesheet">
      <link href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">

    <div class="lb-wrapper">
      <h2 class="sectionsubtitle">MIRAGE-MMMT Leaderboard</h2>
      <div class="legend">
        <span class="legend-item legend-open">Open-Source</span>
        <span class="legend-item legend-proprietary">Proprietary</span>
      </div>

      <style>
        #lb-mmmt th, #lb-mmmt td {
          text-align: center !important;
          vertical-align: middle !important;
        }
      </style>
      
      <table id="lb-mmmt" class="display stripe" style="width:100%">
        <thead>
          <tr>
            <th rowspan="2" class="separator">Name</th>
            <th colspan="3" class="separator">Zero-Shot</th>
            <th colspan="3" class="separator">Chain-of-Thought</th>
          </tr>
          <tr>
            <th class="zs-col">Acc%</th>
            <th class="zs-col">Clarify</th>
            <th class="zs-col">Respond</th>
            <th class="cot-col">Acc%</th>
            <th class="cot-col">Clarify</th>
            <th class="cot-col">Respond</th>
          </tr>
        </thead>
        <tbody></tbody>
      </table>

      <div class="description-wrapper content has-text-justified">
        <p>
          This leaderboard benchmarks large vision-language models on the
          <strong>MMMT</strong> task of the <em>MIRAGE Benchmark</em>.  
          The benchmark utilizes LLMs as Judges method. Scores are averaged over three open-source reasoning models:
          <em>DeepSeek-R1-Distill-Llama-70B</em>,
          <em>Qwen-3-32B</em>, and
          <em>Phi-4-Reasoning</em>.
        </p>
      
        <h3 class="title is-5 mt-5">Metric Descriptions</h3>
        <div class="content">
          <ul>
            <li><strong>Decision Accuracy (Acc&nbsp;%):</strong> Percentage of turns in which the model correctly decides to <em>Clarify</em> or <em>Respond</em>, matching the gold action.</li>
            <li><strong>Clarify&nbsp;Score:</strong> For turns where the model asks a clarification question, judges score (0â€“100) how well the question targets the userâ€™s underlying goal and elicits the missing information.</li>
            <li><strong>Respond&nbsp;Score:</strong> For turns where the model answers directly, judges score (0â€“100) the relevance, usefulness, and goal alignment of the response.</li>
          </ul>
        </div>
      </div>      
    </div>

    
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdn.datatables.net/1.13.6/js/jquery.dataTables.min.js"></script>

    <script>
    fetch("leaderboards/MMMT.json")
      .then(r=>r.json())
      .then(rows=>{
        const metrics = ["zero_shot_acc","zero_shot_clarify","zero_shot_respond",
                        "cot_acc","cot_clarify","cot_respond"];
        const maxVal = Object.fromEntries(
          metrics.map(m=>[m,Math.max(...rows.map(r=>r[m]))]) );

        const table = $('#lb-mmmt').DataTable({
          data: rows,
          dom : 't',
          paging: false,
          order:[[4,'desc']],
          columns:[
            {title:"Model", data:"model", className: "separator"},
            {title:"Acc%",    data:"zero_shot_acc", className:"zs-col"},
            {title:"Clarify", data:"zero_shot_clarify",  className:"zs-col"},
            {title:"Respond", data:"zero_shot_respond",      className:"zs-col separator"},
            {title:"Acc%",  data:"cot_acc",  className:"cot-col"},
            {title:"Clarify",  data:"cot_clarify",  className:"cot-col"},
            {title:"Respond", data:"cot_respond", className:"cot-col"}
          ],
          createdRow:(row,data)=>{
            $(row).addClass(
              data.group==='open' ? 'open-col' : 'proprietary-col');

            metrics.forEach((m,i)=>{
              if(data[m]===maxVal[m]) $('td',row).eq(i+1).addClass('best');
            });
          }
        });
      });
    </script>
    </div>
    </section>

    <!-- ERROR ANALYSIS SECTION -->
    <section id="error-analysis">
      <section id="error-analysis-title" class="hero is-light is-small">
        <div class="hero-body has-text-centered">
          <h1 class="title is-3">
            <i class="fas fa-chart-line" style="margin-right: 0.4rem; color: #3273dc;"></i>Error Analysis
          </h1>      
        </div>
      </section>      
      <div class="container is-max-desktop">
        <!-- Overview -->
        <h2 class="sectionsubtitle" style="text-align: center; margin-top: 2rem;">Error Analysis Overview</h2>
        <p style="margin-bottom: 1.5rem;">
          Our comprehensive error analysis reveals key insights into model performance across different agricultural domains and task types. The analysis examines common failure patterns, domain-specific challenges, and areas where current vision-language models struggle in agricultural expert consultation scenarios.
        </p>
        <p style="margin-bottom: 1.5rem;">
          These visualizations summarize systematic failure patterns in agricultural AI across three tiers: (1) GPT-4.1-only failures, highlighting core domain challenges like fine-grained species distinctions and poor image quality; (2) Qwen-only failures, revealing model-specific issues like vision-language misalignment and confidence errors; and (3) joint failures, showing frontier challenges such as ambiguous visuals and rare species. Bar charts break down the frequency of each error type, while the heatmap offers a side-by-side comparison across models. Together, these plots reveal where models struggle mostâ€”and whyâ€”helping guide future improvements.
        </p>

        <!-- Error Analysis Plots -->
        <div class="columns is-multiline">
          <!-- Error Heatmap -->
          <div class="column is-6">
            <div class="box has-text-centered">
              <h3 class="title is-5">Error Distribution Heatmap</h3>
              <img src="static/figures/Error_Analysis/error_heatmap.png" alt="Error Distribution Heatmap" style="max-width: 100%; height: auto;" />
              <p class="is-size-7 mt-2">Comparison of error categories across GPT-4.1, Qwen2.5, and joint model failures</p>
            </div>
          </div>

          <!-- Plot 1 -->
          <div class="column is-6">
            <div class="box has-text-centered">
              <h3 class="title is-5">Tier 1: Fundamental Domain Challenges (GPT-4.1)</h3>
              <img src="static/figures/Error_Analysis/plot-1.png" alt="GPT-4.1 Domain Errors" style="max-width: 100%; height: auto;" />
              <p class="is-size-7 mt-2">Failures reflecting core agricultural AI challenges such as fine-grained taxonomy and visual ambiguity</p>
            </div>
          </div>

          <!-- Plot 2 -->
          <div class="column is-6">
            <div class="box has-text-centered">
              <h3 class="title is-5">Tier 2: Systematic Gaps in Qwen2.5</h3>
              <img src="static/figures/Error_Analysis/plot-2.png" alt="Qwen2.5 Failures" style="max-width: 100%; height: auto;" />
              <p class="is-size-7 mt-2">Errors where Qwen2.5 fails but GPT-4.1 succeeds, including misalignment and reasoning bias</p>
            </div>
          </div>

          <!-- Plot 3 -->
          <div class="column is-6">
            <div class="box has-text-centered">
              <h3 class="title is-5">Tier 3: Joint Failures â€“ Frontier Cases</h3>
              <img src="static/figures/Error_Analysis/plot-3.png" alt="Joint Model Failures" style="max-width: 100%; height: auto;" />
              <p class="is-size-7 mt-2">Hardest cases involving rare species, overlapping symptoms, and ambiguous visual inputs</p>
            </div>
          </div>
        </div>

        <!-- Key Findings -->
        <div class="content mt-5">
          <h3 class="title is-4">Key Findings</h3>
          <div class="columns">
            <div class="column is-6">
              <h4 class="title is-5">Domain-Specific Challenges</h4>
              <ul>
                <li>Plant disease identification shows the highest error rates due to visual similarity between different diseases</li>
                <li>Pest identification challenges arise from small-scale visual features and seasonal variations</li>
                <li>Management recommendations often lack contextual awareness of geographic and seasonal factors</li>
              </ul>
            </div>
            <div class="column is-6">
              <h4 class="title is-5">Model Limitations</h4>
              <ul>
                <li>Limited fine-grained visual understanding for agricultural entities</li>
                <li>Insufficient domain knowledge for causal reasoning in plant health</li>
                <li>Difficulty in generating practical, actionable recommendations</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Example Section -->
    <section id="MIRAGE Benchmark Examples" class="hero is-light is-small">
    <div class="hero-body has-text-centered">
      <h1 class="title is-3">
      <img src="static/figures/logo/MIRAGE_512x512.png" alt="Icon" style="height: 3rem; margin-right: 0.7rem; position: relative; top: 0.8rem;" />MIRAGE Benchmark Examples
      </h1>      
    </div>
    </section>   
    
    <!-- MIRAGE-MMST Standard Benchmark -->
    <section class="slider-section">
        <h2 class="sectionsubtitle" style="margin-top: 2rem; margin-bottom: -1rem;">MIRAGE-MMST Standard Benchmark</h2>
        <div class="swiper">
          <div class="swiper-wrapper">
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_ID_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Insect_and_Pest_ID_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_Disease_ID_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_Disease_MG_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Weeds_Plants_MG_Standard.drawio.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Insect_and_Pest_MG_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>         
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_Care_Standard.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>    
          </div>

          <div class="swiper-pagination"></div>
        </div>
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </section>

    <!-- MIRAGE-MMST Contextual Benchmark -->
    <section class="slider-section slider-contextual">
        <h2 class="sectionsubtitle" style="margin-top: 4rem; margin-bottom: -1.5rem;">MIRAGE-MMST Contextual Benchmark</h2>
        <div class="swiper">
          <div class="swiper-wrapper">
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_Disease_MG_Contextual.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Weeds_MG_Contextual.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Insect_and_Pest_MG_Contextual.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/Category_Examples/Case_Study_Plant_Care_Contextual.png" style="max-width: 100%; height: auto; min-width: 280px;">
            </div>
          </div>

          <div class="swiper-pagination"></div>
        </div>
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </section>

    <!-- MIRAGE LLM-As-a-Judge -->
    <section class="slider-section slider-contextual">
        <h2 class="sectionsubtitle" style="margin-top: 4rem; margin-bottom: -1.5rem;">Reasoning-LLM-as-A-Judge</h2>
        <div class="swiper">
          <div class="swiper-wrapper">
            <div class="swiper-slide">
                <img src="static/figures/LLM_Judge_Examples/Case_Study_LLMASJudge_ID.png">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/LLM_Judge_Examples/Case_Study_LLMAsJudge_MG.png">
            </div>
            <div class="swiper-slide">
                <img src="static/figures/LLM_Judge_Examples/Case_Study_LLMAsJudge_MMMT.png">
            </div>
          </div>

          <div class="swiper-pagination"></div>
        </div>
        <div class="swiper-button-prev"></div>
        <div class="swiper-button-next"></div>
    </section>

  <!-- Swiper Script -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Swiper/8.4.5/swiper-bundle.min.js"></script>
    <script>
      document.querySelectorAll('.slider-section').forEach(section => {

        const swiperEl      = section.querySelector('.swiper');
        const nextBtn       = section.querySelector('.swiper-button-next');
        const prevBtn       = section.querySelector('.swiper-button-prev');
        const paginationEl  = section.querySelector('.swiper-pagination');

        new Swiper(swiperEl, {
          slidesPerView: 1,
          centeredSlides: true,
          loop: true,
          grabCursor: true,
          pagination: {
            el: paginationEl,
            clickable: true,
          },
          navigation: {
            nextEl: nextBtn,
            prevEl: prevBtn,
          },
        });
      });
    </script>

    <!-- Acknowledgements Section -->
    <section id="acknowledgements" class="section">
      <div class="container is-max-desktop content">
        <h2 class="sectionsubtitle">Acknowledgements</h2>
        <p>
          This work is partly supported by the <a href="https://aice.illinois.edu/" target="_blank">Amazon-Illinois Center on AI for Interactive Conversational Experiences</a> Award, <a href="https://aifarms.illinois.edu/" target="_blank">AIFARMS</a> National AI Institute</a> and <a href="https://digitalag.illinois.edu/" target="_blank">Center for Digital Agriculture</a> at the University of Illinois. We thank the <a href="https://ask.extension.org/" target="_blank">AskExtension</a> team for providing the data. This work used <a href="https://delta.ncsa.illinois.edu/" target="_blank">Delta</a> advanced computing and data resource at University of Illinois Urbana-Champaign and its National Center for Supercomputing Applications through allocation CIS250434 from the <a href="https://access-ci.org/" target="_blank">Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS)</a> program, which is supported by U.S. National Science Foundation grants #2138259, #2138286, #2138307, #2137603, and #2138296. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the sponsors.
        </p>
      </div>
    </section>

    <!-- Citation Section -->
    <section id="citation" class="section">
      <div class="container is-max-desktop content">
        <h2 class="sectionsubtitle">Citation</h2>
        <p>If you find this work useful, please cite our paper:</p>
        <div class="box">
          <pre style="background-color: #f5f5f5; padding: 1rem; border-radius: 4px; overflow-x: auto; font-size: 0.9em; line-height: 1.4;"><code>@article{dongre2025mirage,
  title={MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations},
  author={Dongre, Vardhan and Gui, Chi and Garg, Shubham and Nayyeri, Hooshang and Tur, Gokhan and Hakkani-T{\"u}r, Dilek and Adve, Vikram S},
  journal={arXiv preprint arXiv:2506.20100},
  year={2025}
}</code></pre>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="content has-text-centered">
        <p>
          Website template adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://github.com/MMMU-Benchmark/mmmu-benchmark.github.io/">MMMU</a> under CC BYâ€‘SAâ€‘4.0.
        </p>
      </div>
    </footer>

    <!-- Add this script at the end of the body -->
    <script>
      function toggleAudioPlayer() {
        const audioSection = document.getElementById('audioPlayerSection');
        audioSection.style.display = audioSection.style.display === 'none' ? 'block' : 'none';
      }
    </script>
  </body>
</html>
